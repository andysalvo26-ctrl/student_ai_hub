---
id: CP-PILLAR-ETHICS
type: pillar
derived_from:
  - foundation/content/sections/rules-risks-ethics/index.md
last_updated: 2026-01-22
notes: "Reorganized summary of foundation material; does not add new sources."
---

# Pillar: Rules, Risks, and Ethics of AI

## What this covers

- Why governance and ethics matter in AI
- Common risks and harms associated with AI systems
- Policy, standards, and institutional frameworks
- What this means for students

## Key ideas

- **Ethical concerns**: AI systems can embed biases, contribute to climate degradation, threaten human rights, and compound existing inequalities. Issues include privacy, surveillance, bias, transparency, and the black box problem.
- **Common risks**: Data-intensive technologies can make biased recommendations against marginalized groups. AI systems make decisions that significantly impact people's lives (loans, admissions, jobs, sentencing). Many decisions are not readily explainable (opacity/black box problem).
- **Policy frameworks**: UNESCO has developed global standards for AI ethics. Federal agencies develop standards for AI. Some institutions have created guidelines and frameworks, though policies are not always clear or comprehensive.
- **Student considerations**: Students may encounter AI tools in academic contexts. Understanding ethical considerations is important. Academic integrity involves using AI appropriately and transparently. Accessibility considerations matter when using AI tools.

## Common misunderstandings

- **Bias**: Many believe smart technologies would end human bias due to machine neutrality. However, machines may maintain and substantiate human bias toward women, different ethnicities, the elderly, people with medical impairments, or other groups.
- **Explainability**: Understanding why AI models do what they do is actually very difficult. Systems can be fooled and undermined.
- **Academic integrity**: Concerns include student plagiarism made possible by generative AI and the distinction between concerns about honesty versus concerns about failure to learn.

## How to use this section

This pillar addresses ethical and governance considerations. Use it when:
- Building a "Rules and Risks" or "Ethics" page
- Explaining why governance matters
- Addressing student questions about AI ethics
- Providing context for responsible AI use

Frame issues as concerns and considerations, not absolute judgments. Describe what organizations and researchers have identified, not prescriptive rules.

## Provenance

Derived from:
- `foundation/content/sections/rules-risks-ethics/index.md`

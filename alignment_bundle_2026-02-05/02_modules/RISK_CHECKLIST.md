---
id: CP-MODULE-RISK-CHECKLIST
type: module
derived_from:
  - foundation/content/sections/rules-risks-ethics/index.md
  - foundation/content/sections/ai-tools-you-might-use/index.md
  - foundation/content/sections/using-ai-for-school-and-work/index.md
last_updated: 2026-01-22
notes: "Risk considerations derived from foundation materials; phrased as prompts, not prescriptions."
---

# Risk Checklist: Understanding AI Limitations and Concerns

Use these questions to identify and understand risks associated with AI use.

## Accuracy and Reliability

- Are you aware that AI tools can produce incorrect or fabricated information (hallucinations)?
- Have you verified information provided by AI tools through other sources?
- Are you aware that AI tools may cite sources that don't actually exist?
- Have you considered that AI output is presented with confidence even when incorrect?

## Bias and Discrimination

- Are you aware that AI systems can perpetuate bias and discrimination?
- Have you considered that AI tools are trained on data that may include problematic content?
- Are you screening AI output for bias or focus on particular topics?
- Have you thought about how bias in training data might affect the information you receive?

## Privacy and Data Security

- Are you entering confidential or sensitive information into publicly available AI tools?
- Have you checked your institution's guidelines about data classification levels for different AI tools?
- Are you aware that some AI tools may save data in unknown places?
- Have you considered privacy risks when using AI meeting assistants or collaborative tools?

## Academic Integrity

- Are you using AI to substantially complete assignments, which may be prohibited?
- Have you disclosed your AI use as required?
- Are you citing AI-generated content properly?
- Have you considered whether AI use violates your institution's academic integrity policies?

## Learning and Critical Thinking

- Are you relying solely on AI-generated content for critical academic work?
- Have you considered whether AI use takes away opportunities for deeper learning?
- Are you thinking critically about AI output rather than accepting it uncritically?
- Are you engaging directly with source material, not just AI summaries?

## Explainability and Transparency

- Are you aware that many AI decisions are not readily explainable (black box problem)?
- Have you considered that you may not understand how an AI tool reached its conclusions?
- Are you aware that AI systems can be fooled or fail on tasks humans perform easily?
- Have you thought about the implications of using systems whose reasoning is opaque?

## Tool Limitations

- Are you aware that the AI tool landscape changes frequently?
- Have you considered that tools may provide incomplete information?
- Are you relying on one tool for all research needs, risking missing important information?
- Have you verified claims and sources independently?

## Meeting and Collaboration Tools

- Are you using third-party AI bots in virtual meetings?
- Have you considered privacy, regulatory, and legal risks of AI meeting assistants?
- Are you aware that some bots may scrape calendar information and save meetings?
- Have you checked your institution's guidelines about AI tools in collaborative settings?

---

**Note**: This checklist identifies risks documented in foundation materials. It is not legal or medical advice. Always follow your institution's policies and consult appropriate resources when needed.

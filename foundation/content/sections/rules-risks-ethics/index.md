# Rules, Risks, and Ethics of AI

## Why Governance and Ethics Matter

The rapid rise in artificial intelligence has created many opportunities globally, from facilitating healthcare diagnoses to enabling human connections through social media and creating labour efficiencies through automated tasks. However, according to some international organizations, these rapid changes also raise profound ethical concerns. These arise from the potential AI systems have to embed biases, contribute to climate degradation, threaten human rights and more. According to some research, such risks associated with AI have already begun to compound on top of existing inequalities, resulting in further harm to already marginalised groups. (Source: www_unesco_org__831d1af606b537dd::c0000)

According to some researchers, AI systems are becoming more and more autonomous, apparently rational, and intelligent. This comprehensive development gives rise to numerous issues according to some researchers. In addition to the potential harm and impact of AI technologies on privacy, other concerns include their moral and legal status, their possible moral agency and patienthood, and issues related to their possible personhood and even dignity. According to some researchers, it is common to distinguish issues as of utmost significance with respect to AI and its relation to human society, including autonomous systems, machine bias in law, privacy and surveillance, and the black box problem in AI decision-making. (Source: iep_utm_edu__b4724b6f15ae5245::c0000)

Issues related to privacy, biases, and transparency remain paramount for building AI systems that are both ethical and accurate. As organizations continue to embed AI into their day-to-day processes, establishing frameworks ensuring AI applications are within legal and ethical bounds becomes important. Understanding how ethical issues affect day-to-day operations, such as privacy-related issues, in addition to the broader implications of AI on the economy, the workforce, and the environment, enables leaders to make informed and balanced decisions. (Source: professional_dce_harvard_edu__b348c4377dbfa8f0::c0000, professional_dce_harvard_edu__b348c4377dbfa8f0::c0001)

## Common Risks and Harms

Data-intensive technologies have a high likelihood of making recommendations, predictions, and analyses that are biased against historically marginalized people because the data and infrastructures these technologies use is also biased. Many people believe that the use of smart technologies would put an end to human bias because of the supposed neutrality of machines. However, researchers have come to realize that machines may maintain and even substantiate human bias towards women, different ethnicities, the elderly, people with medical impairments, or other groups. (Source: www_aaup_org__920dd7ff9e19f3c6::c0016, iep_utm_edu__b4724b6f15ae5245::c0016)

AI systems are used to make many sorts of decisions that significantly impact people's lives. AI can be used to make decisions about who gets a loan, who is admitted to a university, who gets an advertised job, who is likely to reoffend, and so on. Since these decisions have major impacts on people, many authors discussing the ethics of AI propose explainability as a basic ethical criterion for the acceptability of AI decision-making. However, many decisions made by an autonomous AI system are not readily explainable to people, which has been called the problem of opacity or the black box problem. (Source: iep_utm_edu__b4724b6f15ae5245::c0018)

In academic contexts, respondents to surveys have expressed concern with student plagiarism made possible by generative AI. Many faculty members noted that they were at least somewhat concerned about preventing academic dishonesty. Some respondents distinguished between concerns about honesty and concerns about failure to learn, highlighting that one of the core goals of higher education is to develop a well-informed and thoughtful citizenry. According to some survey respondents, this distinction suggests that there is a need for higher education to refocus on the relational aspects of education and learning. (Source: www_aaup_org__920dd7ff9e19f3c6::c0013)

## Policy, Standards, and Institutional Frameworks

UNESCO has led the international effort to ensure that science and technology develop with strong ethical guardrails. UNESCO has delivered global standards to maximize the benefits of scientific discoveries while minimizing downside risks, ensuring they contribute to a more inclusive, sustainable, and peaceful world. The UNESCO Recommendation on the Ethics of AI interprets AI broadly as systems with the ability to process data in a way which resembles intelligent behaviour, and it sets out key policy areas where Member States can make strides towards responsible developments in AI. (Source: www_unesco_org__831d1af606b537dd::c0000, www_unesco_org__831d1af606b537dd::c0001)

Federal agencies have engaged in developing standards for artificial intelligence either because these activities are part of their assigned responsibilities or because AI is essential to their current or evolving missions. Executive orders have directed agencies to ensure that technical standards minimize vulnerability to attacks from malicious actors and reflect federal priorities for innovation, public trust, and public confidence in systems that use AI technologies. Agencies have made progress in bolstering AI standards-related knowledge, leadership, and coordination, promoted focused research on the trustworthiness of AI systems, and engaged internationally. (Source: www_nist_gov__590e8afe152537ff::c0000)

Some institutions have created guidelines and frameworks for AI use. According to some research, few institutions have created transparent, equitable policies or provided effective professional development opportunities on AI use. Survey results indicate that many colleges and universities have introduced initiatives around uses of AI for teaching, research, learning, or work, but these initiatives have not always materialized into clear policies on AI implementation. Some institutions have guidelines that address data privacy, accessibility considerations, and appropriate use of AI tools in academic contexts. (Source: www_aaup_org__920dd7ff9e19f3c6::c0002, www_aaup_org__920dd7ff9e19f3c6::c0021)

## What This Means for Students

Students may encounter AI tools in various academic contexts, and understanding ethical considerations surrounding AI use is important. Some institutions have guidelines about what types of data can be entered into publicly available AI tools compared to tools that are licensed by institutions. Many publicly available AI tools should not be used with confidential or sensitive information. Some institutions have guidelines regarding the use of AI tools in meetings and collaborative settings that students are expected to follow. (Source: www_huit_harvard_edu__8f8b35cba5ce9e90::c0000, www_huit_harvard_edu__8f8b35cba5ce9e90::c0001)

Academic integrity involves using AI tools appropriately and transparently. Some institutions treat any use of generative AI as analogous to receiving help from another person. Using generative AI to substantially complete an assignment may be prohibited by institutional policies. Students may need to verify information provided by AI tools and avoid relying solely on AI-generated content for critical academic work. Some tools may provide inaccurate information or make claims that need to be verified through other sources. (Source: ctl_stanford_edu__7f5d76108cf20c2c::c0001, guides_library_georgetown_edu__3fee8ba3bf16d12d::c0000)

According to some research, the implementation of educational technology, including AI, is connected to long-standing inequities in higher education. Some institutions have guidelines that address accessibility considerations when using AI tools, as AI tools have varying levels of accessibility which can disadvantage some users. According to some institutional guidance, student and faculty access to technology and learning experiences and ease of use should be core goals of any technologies introduced. However, many respondents to surveys have also cautioned that these technologies can be so harmful that they should be subjected to thorough review. (Source: www_aaup_org__920dd7ff9e19f3c6::c0014, www_aaup_org__920dd7ff9e19f3c6::c0016)

# Using AI for School and Work

## Appropriate Uses of AI in Coursework

Generative AI tools can support various aspects of coursework when used thoughtfully. Potential uses within course settings include idea generation, such as brainstorming research topics, thesis statements, or outlines. AI tools can also help with clarification by explaining difficult concepts or assignment prompts. For writing tasks, students may use AI for editing and proofreading, checking grammar, tone, and clarity. In technical contexts, AI can provide coding assistance for debugging, explaining algorithms, or generating sample code for learning purposes. (Source: scs_oregonstate_edu__f3cf6e6718506e10::c0001)

Students are using AI tools for a wide range of academic tasks. These include searching for information to quickly find relevant content for coursework and research projects. AI-powered writing assistants can help improve the clarity, conciseness, and accuracy of writing. Students also use AI tools to summarize and paraphrase documents, condensing lengthy articles and research papers into concise summaries. Some students leverage AI to create first drafts of essays and reports, providing a starting point for their own writing and editing process. AI tutors and chatbots can help explain complex concepts by providing clear explanations, examples, and step-by-step guidance. (Source: sites_campbell_edu__62497847e244cab4::c0001)

When considering whether to use AI for coursework, institutional guidance often suggests that students first determine if their instructor has provided expectations about AI use for the specific assignment. Understanding what those expectations are and seeking clarification if needed is typically recommended. Some universities recommend that students seek clarification on what type of use is permitted and what is prohibited. If AI use is allowed, institutional guidance often suggests documenting how AI was employed in the work. (Source: scs_oregonstate_edu__f3cf6e6718506e10::c0001)

## Maintaining Academic Integrity

Academic integrity involves using AI tools appropriately and transparently. Some institutions treat any use of generative AI as analogous to receiving help from another person. Using generative AI to substantially complete an assignment may be prohibited by institutional policies. Students should maintain academic integrity when using AI tools for college assignments by using them to generate ideas or as a learning tool, rather than to complete assignments. (Source: ctl_stanford_edu__7f5d76108cf20c2c::c0001, blog_methodistcollege_edu__35d435c16f5275ac::c0001)

Citing generative AI in academic work is considered important for maintaining transparency and integrity at many institutions. Proper citation reflects both a rigorous scholarly approach to research and ethical considerations surrounding AI technology. When incorporating AI-generated content into academic work, proper citation gives credit to the underlying algorithms and data sources and acknowledges the human input in training and fine-tuning these models. Citing AI sources helps maintain transparency in academic discourse, allowing readers to trace the origins and authenticity of the information presented. Some universities recommend that students check their syllabus to confirm their instructor's expectations for AI citations. (Source: scs_oregonstate_edu__f3cf6e6718506e10::c0002)

Students should disclose any use of generative AI for help with assignments. Instructors may have specific ways they want students to document how and when they utilized AI tools. If students are unclear about whether, how, and when AI use is appropriate, they should consult with their instructor. When in doubt, students should ask questions and document their AI use. (Source: ctl_stanford_edu__7f5d76108cf20c2c::c0001, scs_oregonstate_edu__f3cf6e6718506e10::c0001)

## AI as a Study and Productivity Tool

The relationship between how students use generative AI and their learning depends on how they use the technology. The key question is whether a specific use of AI facilitates or takes away an opportunity for deeper learning. Strategies that involve thinking deeply about material, such as comparing and contrasting concepts, explaining in one's own words, and self-quizzing tend to be more effective than superficial strategies such as highlighting or rereading material. According to some institutional guidance, what's important is that students are using effective strategies to facilitate their learning and not delegating their learning process to an AI tool. (Source: ctl_stanford_edu__7f5d76108cf20c2c::c0004)

AI tools can support study practices in various ways. Effective active reading strategies include previewing the reading and asking questions that might be answered in the text. Generative AI could potentially help with these strategies by generating summaries and questions, though some institutional guidance suggests students consider whether this takes away an opportunity to engage directly with the text themselves. Some universities recommend that students be aware of the risk of introducing inaccuracies into any summaries or questions generated by AI. (Source: ctl_stanford_edu__7f5d76108cf20c2c::c0004)

Artificial intelligence can serve as a supplemental learning tool that makes studying and completing assignments more accessible. However, there are many ways to receive academic support beyond AI tools, including human tutors, academic coaches, advisors, and counselors. While AI tools can provide certain types of support, they have limitations in their ability to provide holistic support for learning challenges or broader life as a student. (Source: blog_methodistcollege_edu__35d435c16f5275ac::c0000, ctl_stanford_edu__7f5d76108cf20c2c::c0003)

## Common Pitfalls and Limitations

AI tools have documented limitations that some institutional guidance suggests students understand. Because of the way AI tools generate responses based on statistical patterns in training data, they will sometimes provide responses that are incorrect, which are called "hallucinations." Additionally, researchers have documented a variety of biases that can exist in training data, such as lack of geographical and population diversity, and note that the algorithms applied to this data can further exacerbate these biases. Research has also shown that AI tools have a tendency to misattribute sources, or in some cases, create citations for sources that don't exist. (Source: ctl_stanford_edu__7f5d76108cf20c2c::c0002)

While the experience of interacting with an AI tool can feel life-like and similar to talking with a human, these tools have serious limitations in their ability to provide comprehensive support. Given these limitations, being able to think critically about the output from AI tools is essential, as not everything they generate will be accurate or useful. Students should be aware that AI tools can demonstrate bias, and they need to screen, read, and recognize items generated that may reflect bias or focus on particular topics. (Source: ctl_stanford_edu__7f5d76108cf20c2c::c0003, blog_methodistcollege_edu__35d435c16f5275ac::c0002)

Many students express concerns about AI's accuracy, reliability, and ethical implications. Students who have used AI to support their studies have expressed concern about receiving incorrect or inaccurate information. According to some research, these concerns highlight the importance of verifying AI-generated content and not relying solely on AI tools for critical academic work. (Source: sites_campbell_edu__62497847e244cab4::c0002)
